1 Introduction



∙∙\bullet “Water is a finite resource, and every drop matters.” — Facebook (now Meta) Sustainability Report 2020 [1].
∙∙\bullet “Fresh, clean water is one of the most precious resources on Earth … Now we’re taking urgent action to support water security and healthy ecosystems.” — Google’s Water Commitment 2023 [2].
∙∙\bullet “Water is a human right and the common development denominator to shape a better future. But water is in deep trouble.” —
U.N. Secretary-General António Guterres at
the U.N. Water Conference 2023 [3].
∙∙\bullet “Historic droughts threaten our supply of water … As the source of both life and livelihoods, water security is central to human and
national security.” —
U.S. White House Action Plan on Global Water Security 2022 [4].



Artificial intelligence (AI) models have witnessed remarkable breakthroughs and success in numerous areas of critical importance to our society over the last decade, including in the ongoing combat against several global challenges such as climate change [5].
Increasingly many AI models are trained and deployed
on power-hungry servers housed inside warehouse-scale data centers, which are often known as energy hogs [6]. Consequently,
despite the numerous benefits and potential of AI,
the environmental footprint of AI models, in particular carbon footprint, has been undergoing public scrutiny, driving the recent progress in AI carbon efficiency [7, 8, 9, 10, 11]. Unfortunately, however, the enormous water footprint
of AI models — many millions of liters of freshwater withdrawn or consumed for
electricity generation
and for cooling the servers — has largely remained under the radar. If not properly addressed, the increasing water usage can become a potential major roadblock to the socially responsible
and environmentally sustainable AI in the future.


Despite the water cycle
through our planet’s natural ecosystem, clean freshwater resource available
and suitable for use is extremely
limited and unevenly distributed across the globe.
In fact, freshwater scarcity is one of the most pressing challenges
shared by all of us
in the wake of the rapidly
growing population and extended megadroughts [12, 13].
Severe water scarcity has already been affecting
4 billion people, or approximately two-thirds
of the global population, for at least one month each year [13, 14].
Without integrated and inclusive approaches to addressing
the global water challenge,
nearly half of the world’s population
will endure severe water stress by 2030 [4],
and
roughly one in every four children worldwide will be living in areas subject to extremely high water stress by 2040
[14].


Warehouse-scale data centers — physical “homes” where
many AI models, especially large ones like GPT-3 and GPT-4 for language services, are physically trained and deployed — are known to be energy-intensive,
collectively accounting for about 1-2% of the global electricity
usage [6].
As such, it is well-known that data centers are responsible for a significant scope-2 carbon footprint associated with location-based electricity generation [15, 16, 17, 7].
Nonetheless, what is much less known is that
data centers are also extremely “thirsty”
— even excluding the embodied water usage due
to supply chains (e.g., scope-3 water for chip manufacturing),
data centers use an enormous amount of water for both
on-site cooling and off-site electricity generation
[18, 19], which,
similar to the scope definitions for carbon emissions,
are referred to as scope-1 and scope-2 water usage, respectively
[20].


Even putting aside the water usage in leased third-party colocation facilities,
Google’s self-owned
data centers alone directly withdrew 25 billion liters
and consumed nearly 20 billion liters of scope-1 water for on-site cooling in 2022, the majority of which was potable water [21].222The detailed difference between
water withdrawal and water consumption
is presented in Section 2.1.
Overall, Google’s data center water usage (both withdrawal and consumption)
in 2022 increased by 20% compared to 2021 [21, 22], and Microsoft’s
total water usage even
saw a 34% increase for the same period [23]. Such significant increases
are likely attributed in part to the growing demand for AI.


In addition, the combined on-site scope-1 and off-site scope-2 global water withdrawal
of Google, Microsoft, and Meta reached an estimate
of 2.2 billion cubic meters in 2022, equivalent to the total
annual water withdrawal (including municipal, industrial, and agricultural usage) of two Denmark [24].333As data centers predominantly rely on the electric grid instead
of being directly powered by renewables [25, 23], our scope-2 water withdrawal (and consumption if applicable) is for location-based electricity generation throughout the paper. The detailed calculation method is available in the appendix. Nonetheless,
Google, Microsoft, and Meta often adopt alternative sustainability programs (e.g., renewable purchasing agreements) to offset their location-based electricity usage and thus have lower or zero market-based carbon and water footprints. The
current ESG reports typically include both location-based and market-based carbon emissions.
This includes 1.5 billion cubic meters of water withdrawal
in the U.S., accounting for about 0.33% of the total U.S. annual water withdrawal.
Simultaneously, out of the total global water withdrawal,
approximately 0.18 billion cubic meters (including 0.13 billion cubic meters
in the U.S.) was “lost” due to evaporation
and hence considered “consumption”, which was even more than the total annual water withdrawal of Liberia (a country of
about 5 million people in West Africa) [24]. Note that
[24] does not provide
country-wide water consumption data. As a rule of thumb, the ratio of water consumption to water withdrawal varies from
5 to 15% in urban areas and from 10 to 50% in rural areas [26].
The growing tension over the enormous water usage between data centers
and human needs may create new environmental risks and even social conflicts
(e.g., the protest against Google’s planned data center construction
in Uruguay amid its extended drought
[27]).


AI represents one of the most prominent and fastest expanding workloads in data centers [7, 28, 29].
For example, a recent study suggests that the global AI demand might
consume 85–134 TWh of electricity in 2027 [30].
If this estimate materializes,
the combined scope-1 and scope-2 operational water withdrawal of global AI may
reach 4.2 – 6.6 billion cubic meters in 2027, which is more than
the total annual water withdrawal of 4 – 6 Denmark
or half of the United Kingdom that is currently under the threat of droughts [31]. If the U.S.
hosts half of the global AI workloads,
the operation of AI may take up about 0.5 – 0.7% of its total annual water withdrawal.
Additionally, the total scope-1 and scope-2 water consumption of global AI
may exceed 0.38 – 0.60 billion cubic meters, i.e., roughly evaporating
the annual water withdrawal of half of Denmark or 2.5 – 3.5 Liberia.
Therefore, AI models can, and also must, take social responsibility
and lead by example in the collective efforts to
combat the global water scarcity challenge by cutting their own water footprint.


Despite its profound environmental
and societal impact, however, the enormous water footprint of AI models
has received disproportionately less attention from the AI community as well as the general public.
For example, while the scope-2 carbon emissions are routinely included as part of AI model cards [32], even scope-1 water usage (either withdrawal or consumption) is missing, let alone scope-2 water usage. This may impede innovations to enable water sustainability and build truly sustainable AI. Importantly, water and carbon footprints are complementary to, not substitutable of, each other for understanding the environmental impacts [33].
Indeed, optimizing for carbon efficiency does not necessarily
result in, and may even worsen, water efficiency, which varies with the energy fuel mixes
for electricity generation and outside weather conditions in its own unique way [34].


On the other hand, unlike many other workloads,
the highly flexible nature of AI workloads opens up
novel scheduling opportunities
to minimize
the water footprint of AI.
(1) Spatial flexibility: Both AI model training
and inference can be processed in
almost any data center with little impact on
latency due to recent advances in data center networking [35].
(2) Temporal flexibility: AI models can be trained
intermittently by a certain deadline.
(3) Performance flexibility:
For the same inference service,
a set of heterogeneous AI models with
distinct computing resource consumption and accuracy performance are often available via model pruning and compression
(e.g., GPT-3 has eight sizes, ranging from
125 million parameters to
175 billion parameters [36]).


Therefore, it is truly a critical time to uncover and address AI models’ secret water footprint amid the increasingly severe freshwater scarcity crisis, worsened extended droughts, and quickly aging public water infrastructure. The urgency can also be reflected
in part by the recent commitment to “Water Positive by 2030”
by increasingly many companies, including Google [22],
Microsoft [37] and Meta [38].


In this paper, we make the first-of-its-kind efforts to uncover the secret water footprint of AI models. Specifically,
we present a principled methodology to estimate the total water (both withdrawal and consumption) footprint, including both operational
water and embodied water. By taking the GPT-3 model (with 175 billion parameters) for language services as a concrete example [36],
we show that
training GPT-3 in Microsoft’s state-of-the-art U.S. data centers
can consume a total of 5.4 million liters of water, including
700,000 liters of scope-1 on-site water consumption.
Additionally, GPT-3 needs to “drink” (i.e., consume) a 500ml bottle of water for roughly 10-50 responses, depending on
when and where it is deployed. These numbers may increase for the newly-launched GPT-4
that reportedly has a substantially larger model size [39].


Next, we show that
WUE (Water Usage Effectiveness, a measure of water efficiency)
varies both spatially and temporally, implying
that judiciously deciding “when” and “where” to train a large AI model can significantly
cut the water footprint.
We also point out the need for increasing transparency
of AI models’ water footprint, including disclosing more information
about operational data and keeping users informed
of the runtime water efficiency.
Finally, we highlight the necessity
of holistically addressing water footprint along with carbon footprint
to enable truly sustainable
AI — the water footprint of AI models can no longer stay under
the radar.





2 Background


2.1 Water Withdrawal vs. Water Consumption

There are two related but different types of water usage — water withdrawal (a.k.a. water abstraction) and water consumption, both of which are important for holistically understanding the impacts on water stress and availability [40, 41].


∙∙\bullet Water withdrawal: It refers to
freshwater taken from the ground or surface water sources, either temporarily
or permanently, and then used for agricultural, industrial or municipal uses (normally excluding water used for hydroelectricity generation) [42]. As water is a finite shared resource,
water withdrawal
indicates the level of competition as well as dependence on water resources among different sectors.
In an emergency, a country may only have enough water withdrawal for 48 hours,
and the change in water quality after withdrawal contributes to water stress levels
for downstream usage [40].


∙∙\bullet Water consumption:
It is defined
as “water withdrawal minus water discharge”, and means
the amount of water “evaporated, transpired, incorporated into products or crops, or otherwise removed from the immediate water environment” [41]. Water consumption reflects the impact of water use on downstream water availability and is crucial for evaluating watershed-level water scarcity [40].


These two types of water usage also correspond to two different types
of water footprints, i.e., water withdrawal footprint (WWF) [43] and
water consumption footprint (WCF), respectively [6, 19]. By default,
water footprint refers to the water consumption footprint unless otherwise specified.




2.2 How Does AI Use Water?

Following the scope definition for carbon emissions
[25],
we describe AI’s water usage according to on-site
water for server cooling (scope 1), off-site water for
electricity generation (scope 2), and supply-chain water
for server manufacturing (scope 3).



2.2.1 Scope-1 Water Usage

Computing servers, especially those equipped with multiple graphic processing
units (GPUs) hosting AI workloads, are energy-intensive.
Nearly all the server energy is converted into heat, which must then be removed
from the data center server room to avoid overheating. There are two basic types
of cooling systems — cooling towers and outside air cooling — which both use water and we describe as follows.


Figure 1: An example of data center’s operational water usage: on-site scope-1 water
for server cooling (via cooling towers in the example), and off-site scope-2 water usage
for electricity generation.
The icons for AI models are only for illustration purposes.


Cooling towers. Many data centers, including
some of
Google’s data centers [22], use cooling towers as the heat rejection mechanism.
While the specific designs may differ,
a common system contains two water loops as illustrated in Figure 1: one closed loop between the chiller and
data center server room, and one open loop between the cooling tower and the chiller.
The closed loop does not withdraw or consume water — the water circulating inside is pumped from the chiller into the data center to cool down the air handling unit’s supply
air in order to maintain a proper server inlet temperature, and the
warm water that absorbs heat from the hot air returns to the chiller.
In other words, the closed-loop water simply transfers the heat from
the hot air exiting the servers’ outlets to the chiller unit, which then must be cooled by further rejecting the heat into the outside environment. The chiller may be turned off and operate
in a natural “bypass” mode for energy saving when the outside temperature is sufficiently low.


While air-cooled chillers are available,
a more efficient design is to use an open loop that carries water
to move the heat
from the chiller to a cooling tower. Along the open loop, some water
gets evaporated (i.e., “consumed”) in the cooling tower to dissipate heat into the environment, while the remaining water moves to the chiller unit to further absorb heat. Additionally, the remaining non-evaporated water in the open loop can only be cycled up to a few times (e.g., 3 – 10, depending on the water quality) and must be discharged to avoid high concentrations of salt and minerals.
Thus, to keep the cooling tower working, new water must be constantly added
to make up for the evaporated water and discharged water.
Importantly, clean freshwater (potable water in many cases [21]) is needed to avoid pipe clogs and/or
bacterial growth.


For cooling towers, water withdrawal refers to the amount of water added to the cooling tower (including both evaporated water and discharged water), while
water consumption exclusively indicates the amount of evaporated water. Typically,
given good water quality (that allows more water cyles before discharging), roughly 80% of water withdrawal is evaporated and considered “consumption” [21]. On average, depending on the
weather conditions and operational settings, data centers can
evaporate about 1 – 9 liters per kWh of server energy (about 1 L/kWh for Google’s annualized global number [21] and
9 L/kWh for a large commercial data center during the summer in Arizona
[44]).


Outside air cooling with water assistance. When the climate condition is appropriate, data centers may use “free” outside air to directly cool
down the servers without cooling towers. A large amount of outside air
is blown through the servers and then exhausted to the outside.
For outside air cooling, however, water evaporation is still needed
when the outside air is too hot (e.g., higher than 81 or 89 degrees Fahrenheit);
additionally, water is needed for humidity control when the outside air is too dry [45, 38, 46]. The added water is considered withdrawal, out of which about
70% is evaporated based on Meta’s report [25].
Typically, the average water efficiency of outside air cooling is better than
that of cooling towers (e.g., water consumption of 0.2 L/kWh averaged
over Meta’s global data centers) [25].
Nonetheless, when the outside air temperature is high, outside air
cooling evaporates a significant amount of water, thus resulting in a low
average but high peak water withdrawal. This may be especially problematic
when the demand for water is also higher for other users on certain
hot summer days [47].
Additionally, the application of outside air cooling may have significant challenges in hot regions and/or
for many colocation facilities that are located in business districts.


Some data centers may also use a hybrid design that dynamically switches between cooling tower and outside air cooling [48].
Note also that AI servers
often have high power densities due to specialized designs, including
multiple GPUs and/or purpose-built hardware, to speed
up AI model training and inference. As such, on-chip liquid cooling may be employed: closed-loop circulating liquid
directly moves the heat from the servers to the data center facility (e.g., the facility’s cooling water loop).
Then, the heat moved to the facility will be rejected by cooling towers
or simply outside air [48].




2.2.2 Scope-2 Water Usage

Despite the increasing adoption of solar and wind energy,
73% of the utility-scale electricity generated in the U.S. came from thermoelectric power plants in 2021 [49].
Thus, electricity generation does not only emit carbon,
but also uses a huge amount of water
[41, 20].
Just like scope-2 carbon emissions, data centers, including
AI workloads, are also responsible for off-site scope-2 water
usage due to electricity generation [19, 6, 44].
Different thermoelectric power plants (e.g., coal and natural gas) use different amounts of water for each kWh generation. The amount of water withdrawal also depend
on the cooling techniques [49].
Typically, water withdrawal due to hydropower generation is excluded from the calculation of water withdrawal, but water consumption due to expedited water evaporation from hydropower generation is often included [6].
In many countries, thermoelectric power is among
the top sectors (including agriculture) in terms of water withdrawal
and water consumption [41].
For electricity generation,
the U.S. national average water withdrawal and consumption
are
estimated at about 43.8 L/kWh [49]
and
3.1 L/kWh [20], respectively.
While Google and Microsoft did not disclose
their scope-2 water usage,
Meta’s self-reported average
water consumption for its global data center fleet
was 3.58 L/kWh
(i.e., 41,172,356 cubic meters divided by 11,508,131 MWh) in 2022
[25].




2.2.3 Scope-3 Water Usage

AI chip and server manufacturing uses a huge amount
of water [50, 51]. For example, ultrapure water is needed
for wafer fabrication, and clean water is also needed for keeping
semiconductor plants cool. Overall, a large semiconductor plant
may withdraw several million liters of water each day [52].
Importantly, the discharged water can contain toxic chemicals
and/or hazardous wastes, which need additional processing before
reused for other purposes.
While water recycling at semiconductor plants can effectively
reduce water withdrawal, the water recycling rate in many
cases can still remain low, e.g., the average
recycling rate for wafer plants and semiconductor plants
in Singapore are 45% and 23%, respectively [51].
Unlike scope-1 and scope-2 water usage, the data for scope-3 water
usage (including withdrawal and consumption) remains largely obscure.







3 Estimating Water Footprint of AI Models

While an AI model’s water footprint depends in part on its energy consumption, such dependency varies spatially and temporally. As a result, simply
multiplying the AI model’s energy consumption by a constant and fixed WUE may not yield
an accurate estimate of AI models’ water footprint.
Next, by accounting for time-varying WUE, we present a methodology
for a fine-grained estimate of an AI model’s water footprint.
Here, we focus on water consumption
footprint to describe our water footprint modeling methodology.
To obtain the water withdrawal footprint, we simply
replace the WUE with a new coefficient that represents
water withdrawal efficiency.



3.1 Operational Water Footprint

We collectively refer to on-site scope-1 water and off-site scope-2 water
as the operational water. To model the operational water footprint,
we need to know the on-site WUE and off-site WUE.


∙∙\bullet On-site WUE. We denote
the on-site scope-1 WUE at time t𝑡t by ρs​1,tsubscript𝜌𝑠1𝑡\rho_{{s1},t}, which
is defined as the ratio of the on-site water consumption to server energy
consumption and
varies over time depending on the outside temperature.
Concretely, ρs​1,tsubscript𝜌𝑠1𝑡\rho_{{s1},t} increases significantly for cooling towers
when the outside
wet bulb temperature increases [53, 34], and
increases for outside air cooling when the outside
dry bulb temperature is too hot or the humidity is too low [38, 46].
For example, the monthly average on-site WUE for a commercial
data center reaches as high as about 9 L/kWh in the summer and becomes
about 4 L/kWh in the winter [44]. Thus, ρs​1,tsubscript𝜌𝑠1𝑡\rho_{{s1},t} can be modeled as a
function in terms of the outside weather condition based on empirical operational data (see [34] for
an example of on-site WUE based on cooling towers).


∙∙\bullet Off-site WUE.
We denote the off-site scope-2 WUE at time t𝑡t as ρs​2,tsubscript𝜌𝑠2𝑡\rho_{s2,t}, which
is defined as the ratio of off-site water consumption for each kWh of electricty
generation and
measures the electricity water intensity factor (EWIF).
In practice, ρs​2,tsubscript𝜌𝑠2𝑡\rho_{s2,t}
depends on the energy fuel mixes (e.g., coal, nuclear, hydro) as well as cooling techniques used by power plants [54, 55, 20].
Since electricity produced by different energy fuels becomes
non-differentiated once entering the grid, we consider the average method
to calculate ρs​2,tsubscript𝜌𝑠2𝑡\rho_{s2,t}, which can be estimated as
ρs​2,t=∑kbk,t×E​W​I​Fk∑kbk,tsubscript𝜌𝑠2𝑡subscript𝑘subscript𝑏𝑘𝑡𝐸𝑊𝐼subscript𝐹𝑘subscript𝑘subscript𝑏𝑘𝑡\rho_{s2,t}=\frac{\sum_{k}{b_{k,t}}\times EWIF_{k}}{\sum_{k}{b_{k,t}}}
where bk,tsubscript𝑏𝑘𝑡b_{k,t} denotes the amount of electricity generated from fuel type k𝑘k at time t𝑡t for the grid serving the
data center under consideration, and E​W​I​Fk𝐸𝑊𝐼subscript𝐹𝑘EWIF_{k} is the EWIF for fuel type k𝑘k [56, 57].
As a result,
variations in energy fuel mixes of electricity generation (to meet various demand levels) result
in temporal variations of the off-site WUE. Moreover,
the off-site WUE also varies by location, because each fuel type has its own distinct WUE
and the energy fuel mix is typically different between states as some states may use less water-efficient energy generation than others [20, 55, 18, 34].


∙∙\bullet Operational water footprint.
The on-site scope-1
water consumption can be obtained by multiplying AI’s energy consumption
with the on-site WUE, while the off-site scope-2 water consumption depends on the electricity usage
as well as the local off-site WUE.
Consider a time-slotted model t=1,2,⋯,T𝑡12⋯𝑇t=1,2,\cdots,T, where
each time slot can be 10 minutes to an hour depending on how frequently
we want to assess the operational water footprint, and T𝑇T is the total
length of interest (e.g., training stage, total inference stage,
or a combination of both).
At time t𝑡t, suppose that an AI model uses energy etsubscript𝑒𝑡e_{t} (which can be measured using power meters and/or servers’ built-in tools),
the on-site WUE is ρs​1,tsubscript𝜌𝑠1𝑡\rho_{s1,t},
the off-site WUE is ρs​2,tsubscript𝜌𝑠2𝑡\rho_{s2,t},
and the data center hosting the AI model has a power
usage effectiveness (PUE) of θtsubscript𝜃𝑡\theta_{t} that accounts for the non-IT energy such as cooling systems and power distribution losses.
Then, the total water footprint W𝑊W of the AI model can be written
as



W​a​t​e​r​O​p​e​r​a​t​i​o​n​a​l=∑t=1Tet⋅[ρs​1,t+θt⋅ρs​2,t].𝑊𝑎𝑡𝑒𝑟𝑂𝑝𝑒𝑟𝑎𝑡𝑖𝑜𝑛𝑎𝑙superscriptsubscript𝑡1𝑇⋅subscript𝑒𝑡delimited-[]subscript𝜌𝑠1𝑡⋅subscript𝜃𝑡subscript𝜌𝑠2𝑡\begin{split}WaterOperational=\sum_{t=1}^{T}e_{t}\cdot\left[\rho_{s1,t}+\theta_{t}\cdot\rho_{s2,t}\right].\end{split}

(1)


If we are interested in the operational water withdrawal footprint,
we simply replace ρs​1,tsubscript𝜌𝑠1𝑡\rho_{s1,t} and ρs​2,tsubscript𝜌𝑠2𝑡\rho_{s2,t}
with new values that represent the on-site and off-site water withdrawal
efficiencies, respectively.




3.2 Embodied Water Footprint

The embodied water footprint is primarily due to server manufacturing.
Like accounting for embodied carbon footprint [58, 16],
the total water for manufacturing is amortized over the lifespan of a server. Specifically, suppose
that it uses W𝑊W amount of water for manufacturing the AI servers in total
and the servers are expected to last an effective period of T0subscript𝑇0T_{0} time (i.e.,
the total lifespan multiplied by the average utilization rate).
Then, for a total
length T𝑇T of interest (e.g., training stage, total inference stage,
or a combination of both), the embodied water footprint
for AI servers is obtained by adding up the amortized
per-time manufacturing water over the total time T𝑇T,
i.e.,



W​a​t​e​r​E​m​b​o​d​i​e​d=T⋅WT0.𝑊𝑎𝑡𝑒𝑟𝐸𝑚𝑏𝑜𝑑𝑖𝑒𝑑⋅𝑇𝑊subscript𝑇0\begin{split}WaterEmbodied=\frac{T\cdot W}{T_{0}}.\end{split}

(2)




By adding up the operational and embodied water footprints,
we obtain the total water footprint as



W​a​t​e​r​T​o​t​a​l=∑t=1Tet⋅[ρs​1,t+θt⋅ρs​2,t]+T⋅WT0.𝑊𝑎𝑡𝑒𝑟𝑇𝑜𝑡𝑎𝑙superscriptsubscript𝑡1𝑇⋅subscript𝑒𝑡delimited-[]subscript𝜌𝑠1𝑡⋅subscript𝜃𝑡subscript𝜌𝑠2𝑡⋅𝑇𝑊subscript𝑇0\begin{split}WaterTotal=\sum_{t=1}^{T}e_{t}\cdot\left[\rho_{s1,t}+\theta_{t}\cdot\rho_{s2,t}\right]+\frac{T\cdot W}{T_{0}}.\end{split}

(3)




Our methodology for estimating AI models’ water footprint is general and applies
to data centers with any cooling systems.
We simply plug in the values ρs​1,tsubscript𝜌𝑠1𝑡\rho_{s1,t}, θtsubscript𝜃𝑡\theta_{t}
and ρs​2,tsubscript𝜌𝑠2𝑡\rho_{s2,t} to obtain a fine-grained estimate
of the operational water footprint.
Alternatively,
to obtain a rough estimate,
we can use the (annualized) average values
for these parameters and the estimated AI server energy
consumption (e.g., by multiplying the average GPU power consumption with
the total training or inference time) [7].




3.3 Case Study: Estimating GPT-3’s Operational Water Consumption Footprint

Table 1: Estimate of GPT-3’s average operational water consumption footprint. “*” denotes data centers under construction as of July 2023,
and the PUE and WUE values for these data centers are based on Microsoft’s
projection.



Location
PUE



WUE

(L/kWh)




Electricity Water

 Intensity

(L/kWh)


Water for Training (million L)


Water for Each Inference (mL)




# of Inferences

 for 500ml

 Water






On-site


Water






Off-site


Water






Total


Water






On-site


Water






Off-site


Water






Total


Water





U.S. Average
1.170
0.550
3.142
0.708
4.731
5.439
2.200
14.704
16.904
29.6


Wyoming
1.125
0.230
2.574
0.296
3.727
4.023
0.920
11.583
12.503
40.0


Iowa
1.160
0.190
3.104
0.245
4.634
4.879
0.760
14.403
15.163
33.0


Arizona
1.223
2.240
4.959
2.883
7.805
10.688
8.960
24.259
33.219
15.1


Washington
1.156
1.090
9.501
1.403
14.136
15.539
4.360
43.934
48.294
10.4


Virginia
1.144
0.170
2.385
0.219
3.511
3.730
0.680
10.913
11.593
43.1


Texas
1.307
1.820
1.287
2.342
2.165
4.507
7.280
6.729
14.009
35.7


Singapore
1.358
2.060
1.199
2.651
2.096
4.747
8.240
6.513
14.753
33.9


Ireland
1.197
0.030
1.476
0.039
2.274
2.313
0.120
7.069
7.189
69.6


Netherlands
1.158
0.080
3.445
0.103
5.134
5.237
0.320
15.956
16.276
30.7


Sweden
1.172
0.160
6.019
0.206
9.079
9.284
0.640
28.216
28.856
17.3


Mexico*
1.120
0.056
5.300
0.072
7.639
7.711
0.224
23.742
23.966
20.9


Georgia*
1.120
0.060
2.309
0.077
3.328
3.406
0.240
10.345
10.585
47.2


Taiwan*
1.200
1.000
2.177
1.287
3.362
4.649
4.000
10.448
14.448
34.6


Australia*
1.120
0.012
4.259
0.015
6.138
6.154
0.048
19.078
19.126
26.1


India*
1.430
0.000
3.445
0.000
6.340
6.340
0.000
19.704
19.704
25.4


Indonesia*
1.320
1.900
2.271
2.445
3.858
6.304
7.600
11.992
19.592
25.5


Denmark*
1.160
0.010
3.180
0.013
4.747
4.760
0.040
14.754
14.794
33.8


Finland*
1.120
0.010
4.542
0.013
6.548
6.561
0.040
20.350
20.390
24.5





The core of ChatGPT, a popular online service, is
a large language model built based on subsequent versions
of GPT-3. Due to the limited public data available for GPT-4,
we now present a case study to estimate GPT-3’s operational
water consumption footprint.
In particular, we consider the full GPT-3 model with 175 billion parameters, which is also the one considered for estimating its carbon
footprint [7].
We exclude embodied water footprint due to the lack of public
data for scope-3 water usage in GPT-3’s supply chain.
We choose GPT-3 as Microsoft publishes its location-wise
WUE and PUE [46], whereas such information is often limited for other companies.
The results are shown in Table 1.
Note that the newer GPT-4 model currently used by ChatGPT
reportedly has a significantly larger model size [39]
and hence likely consumes more training and inference energy than GPT-3 on average.



3.3.1 Training

GPT-3 was trained and deployed by OpenAI in Microsoft’s data centers,
with an estimated training energy of 1287 MWh [36, 59]. While Microsoft
recently disclosed that OpenAI
had used its Iowa data center for training some models such as GPT-4 [47],
the specific data center location for training GPT-3 has yet to be public.
Thus, we estimate the water consumption footprint for training GPT-3 by considering
different data center locations, including non-U.S. data centers
for references.
In line with the practice of estimating the carbon footprint
[7], we use the annualized average
on-site power usage effectiveness (PUE)
and water usage effectiveness (WUE) for each data center location.
The PUE and WUE for each data center location are based on Microsoft’s most recent disclosure [46],
while the average U.S. data center PUE and WUE are based on [60].
For data centers under construction, we use the PUE and WUE data
projected by Microsoft.


To estimate the off-site scope-2 water consumption, we use
the regional electricity water intensity provided
by [20] wherever applicable to ensure maximum data consistency.
Specifically, for each U.S. data center location, we use
the eGRID-level average electricity water intensity [20].
For Microsoft’s Taiwan data center,
we use the average electricity water intensity
of 2.177L/kWh provided by
[61].
For
Microsoft’s Singapore data center,
we calculate the electricity water intensity
by considering a mixture of 96% natural gas
and 4% renewables (with zero water operational water consumption)
as Singapore’s energy
sources for electricity generation [62]
and using Malaysia’s water intensity for
natural gas-based electricity generation provided
by [20] as a substitute.
For all the other
non-U.S. data center locations, we use their country-level
average electricity water intensities from [20].




3.3.2 Inference

AI models are often deployed globally for inference
to minimize the latency and/or comply with privacy regulations. We estimate the water consumption footprint
for GPT-3 inference in different data centers.
The PUE, WUE and electricity water intensity are the
same as those used for estimating the training water footprint.
The official estimate shows that GPT-3 consumes on the order of 0.4kWh electricity to generate
100 pages of content (e.g., 0.004kWh per page) [36].
Meanwhile, the average inference energy for BLOOM (a language model with a slightly larger size of 176 billion parameters
than GPT-3) is about 0.00396kWh per request (914kWh for 230,768 requests), including both dynamic energy
and amortized idle energy [16]. BLOOM was deployed on Google cloud,
which has a similar energy efficiency as Microsoft’s Azure cloud.
Thus, we consider 0.004kWh as the inference energy consumption per request.


Remarks. As Microsoft only reports its
annualized PUE and
on-site scope-1 WUE [60],
the actual PUE and WUE at certain times of the year can be different from the annualized numbers.
Moreover, if GPT-3 is deployed in third-party
colocation data centers other than Microsoft’s own state-of-the-art
data centers, the water footprint for inference may also be
higher due to the often worse PUE and WUE in colocation data centers.
Our electricity water intensity
for the U.S. (i.e., 3.14L/kWh on average)
is lower
than 7.6L/kWh used by
Lawrence Berkeley National Laboratory to estimate the offsite
scope-2 water consumption [6].
Therefore,
our estimated water footprint for GPT-3 can absorb some potential discrepancies in the estimated inference energy of
0.004kWh, while noting that GPT-4 currently used by ChatGPT may
use different, and likely more, energy than GPT-3 on average due to the reportedly larger model size [39].







4 Our Findings and Recommendations

We provide our findings and recommendations to address
the water footprint of AI models, making
future AI
more socially responsible and environmentally sustainable.





(a) eGRID-level carbon/water efficiency




(b) Hourly carbon/water efficiency





(c) Hourly energy fuel mixes



Figure 2: (a) The U.S. eGRID-level scope-2 water consumption intensity factor vs. carbon emission rate [63, 20]. The dashed
line represents a linear regression model, showing that the eGRID-level
scope-2 carbon emission and water consumption efficiencies are not aligned.
(b) A 5-day snapshot of scope-2 carbon emission rate and water consumption intensity
for electricity generation serving Virginia, starting from April 4, 2022. The values are calculated
based on the energy source mixes, carbon emission rate
and water consumption intensity for each energy fuel type [64, 20, 63]. The scope-2 carbon and water efficiencies only have a Pearson correlation coefficient of 0.06, showing a weak correlation.
(c) A 5-day snapshot of energy fuel mixes serving Virginia, starting from April 4, 2022 [64].



4.1 “When” and “Where” Matter

Judiciously deciding “when” and “where” to train a large AI model can significantly
affect the water footprint.
As shown in Figures 2(a)
and 2(b),
the water efficiency has spatial-temporal diversity — on-site water efficiency changes due to variations of outside weather conditions, and off-site water efficiency changes due to variations of the grid’s energy fuel mixes to meet time-varying demands (Figure 2(c)) [44, 65]. In fact,
water efficiency varies at a much faster timescale than monthly or seasonably.
Therefore, by exploiting spatial-temporal diversity of water efficiency,
we can dynamically schedule AI model training and inference to
cut the water footprint. For example, if we train
a small AI model, we can schedule the training task at midnight and/or
in a data center location with better water efficiency.
Likewise, some water-conscious users may prefer to use
the inference services of AI models during water-efficient hours and/or in water-efficient
data centers, which can contribute to the reduction
of AI’s water footprint.




4.2 More Transparency is Needed

To exploit the spatial-temporal diversity of water efficiency, it is crucial
to have better visibility of the runtime water efficiency and increase transparency
by keeping the AI model developers as well as
end-users informed. Nonetheless, such data is often lacking.
For example, even scope-1 water usage (either withdrawal or consumption)
is not included in today’s AI model cards (e.g., [32]), not to mention
the scope-2 water usage. Additionally,
there is very limited data available for embodied water usage by chip making,
which adds challenges to a holistic lifecycle view of AI’s water footprint.


We recommend AI model developers and data center operators be more transparent. For example,
what are the runtime (say, hourly) on-site scope-1 WUE and off-site
scope-2 WUE? What about
the water footprint of AI models trained and/or deployed in third-party colocation data centers? Such information will be of great value
to the research community and the general public. As
the first step, we recommend that the scope-1 and scope-2 water usage information be included in AI’s model cards.




4.3 “Follow the Sun” or “Unfollow the Sun”

To cut the carbon footprint, it is preferable to “follow
the sun” when solar energy is more abundant. Nonetheless,
to cut the water footprint, it may be more appealing to
“unfollow the sun” to avoid high-temperature hours
of a day when WUE is high.
This conflict
can be shown in Figure 2(a),
where we see
that the scope-2 water consumption intensity factor and
carbon emission
rate are not well aligned: minimizing one footprint might increase
the other footprint.
Thus, to judiciously achieve a balance between
“follow
the sun” for carbon efficiency
and “unfollow
the sun” for water efficiency, we need to reconcile
the potential water-carbon conflicts by using
new and holistic approaches.
In other words, only focusing on AI models’ carbon footprint alone
may be insufficient to enable truly sustainable
AI.






5 Related Works

The growing resource and energy consumption of AI
models have placed an increasing emphasis on sustainable AI
[36, 66, 7, 59, 9, 8, 10].
Specifically, a variety of approaches can be leveraged to make
AI more sustainable,
including novel GPU and accelerator designs [67, 68, 7],
efficient AI model
training and inference [69, 70],
carbon-aware AI model scheduling [10, 15],
green data center designs [71, 72, 73, 74].
These studies
have mostly focused
on scope-2 carbon footprint, neglecting water footprint
which is another environmental
footprint [75, 76, 77].
Crucially,
despite the correlation between water footprint and carbon footprint, the existing techniques that optimize for carbon efficiency
do not necessarily equate to, and may even worsen, water efficiency [34].


Data centers have increasingly adopted climate-conscious cooling
system designs (e.g., air-side economizers
and purifying non-potable water) [21, 38].
These water-saving approaches
can be viewed as supply-side solutions — saving water
while supplying enough cooling to meet the given demand. But,
the demand-side management — cooling demands
are affected by “when” and “where”
AI models are trained and used — is not addressed.
Additionally, these approaches only focus on the on-site scope-1 water usage, whereas the off-site scope-2 water usage with time-varying
off-site WUE due to variations in energy fuel mixes is not addressed.


Finally, it is worth mentioning that some data center operators have also begun
to build water restoration projects to indirectly compensate
for their water footprint [21, 37, 25]. While this is certainly encouraging, it is
is an offsetting method (like building renewables
projects to offset location-based carbon emissions)
and hence orthogonal
to reducing water withdrawal or consumption in the first place.





6 Conclusion

In this paper, we recognize the enormous water usage
as a critical concern for socially responsible and environmentally sustainable AI.
Our key contribution
is to make the first-of-its-kind efforts to uncover the secret water footprint of AI models. Specifically,
we present a principled methodology to estimate AI’s water footprint.
Then, using GPT-3 as an example, we show that a large AI model can consume a stunning amount of
water in the order of millions of liters for training. We also
discuss that the scope-1 and scope-2 water efficiencies
vary spatially and temporally —
judiciously deciding “when” and “where” to run a large AI model can significantly
cut the water footprint.
In addition, we point out the need for increased transparency
of AI models’ water footprint, and highlight the necessity
of holistically addressing water footprint along with carbon footprint
to enable truly sustainable AI.


AI models’ water footprint can no longer stay under
the radar — water footprint must be addressed as a priority as part of the collective
efforts to combat global water challenges.