{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utility import get_root\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import Tuple, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_flops(model: str, input_size: Tuple[int, int], training_strategy: str, sample_count: int, estimated_epochs: int) -> float:\n",
    "    path_to_flops = os.path.join(get_root(), \"data\", \"model_flops\", \"model_flops.xlsx\")\n",
    "    flops_df = pd.read_excel(path_to_flops)\n",
    "\n",
    "    model_info = flops_df[flops_df[\"Model\"] == model]\n",
    "\n",
    "    if model_info.empty:\n",
    "        raise ValueError(f\"Model {model} not found in the flops database\")\n",
    "    \n",
    "    model_type = model_info['Type'].iloc[0]\n",
    "    original_input_size = model_info['Input Size'].iloc[0].split()[0]\n",
    "\n",
    "    if model_type == 'Vision':\n",
    "        width, height = map(int, original_input_size.split('x'))\n",
    "        scaling = (input_size[0] * input_size[1]) / (width * height)\n",
    "    else:\n",
    "        scaling = input_size[0] / int(original_input_size)\n",
    "\n",
    "    if training_strategy in [\"Fine-tuning the whole model\", \"Full Training\"]:\n",
    "        return estimated_epochs * sample_count * model_info['FLOPs'].iloc[0] * scaling * 3\n",
    "    elif training_strategy == \"Last Layer Learning\":\n",
    "        return estimated_epochs * sample_count * 2 * model_info['Last Layer FLOPs'].iloc[0] + model_info['FLOPs'].iloc[0] * scaling\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported training strategy: {training_strategy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_time(flops: float, gpu: str, training_strategy: str, tflops: str) -> float:\n",
    "    path_to_gpu = os.path.join(get_root(), \"data\", \"gpus.csv\")\n",
    "    gpu_df = pd.read_csv(path_to_gpu)\n",
    "    gpu_info = gpu_df[gpu_df[\"name\"] == gpu]\n",
    "\n",
    "    if gpu_info.empty:\n",
    "        raise ValueError(f\"GPU {gpu} not found in the flops database\")\n",
    "    \n",
    "    return flops / gpu_info[tflops].iloc[0] / 1e+12 if training_strategy in [\"Full Training\", \"Fine-tuning the whole model\"] else flops / gpu_info[tflops].iloc[0] / 1e+12 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kwh_consumption(gpu_name, time_seconds):\n",
    "    path_to_gpu = os.path.join(get_root(), \"data\", \"gpus.csv\")\n",
    "    gpu_df = pd.read_csv(path_to_gpu)\n",
    "\n",
    "    tdp_watts = gpu_df.loc[gpu_df['name'] == gpu_name, 'tdp_watts'].values[0]\n",
    "    \n",
    "    # Convert TDP from watts to kilowatts\n",
    "    tdp_kw = tdp_watts / 1000\n",
    "    \n",
    "    # Convert time from seconds to hours\n",
    "    time_hours = time_seconds / 3600\n",
    "    \n",
    "    # Calculate the energy consumption in kWh\n",
    "    energy_consumption_kwh = tdp_kw * time_hours\n",
    "    \n",
    "    return energy_consumption_kwh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.106196446814041e+19\n"
     ]
    }
   ],
   "source": [
    "a = estimate_flops(\"fasterrcnn_resnet50_fpn\", (256, 256), \"Fine-tuning the whole model\", 1000000, 40)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = estimate_time(a, \"RTX 3080 TI\", \"Fine-tuning the whole model\", \"TFLOPS16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.049589148331236"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = calculate_kwh_consumption(\"RTX 3080 TI\", b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "\n",
    "\n",
    "def get_tflops_value(perf_data, tflops_type):\n",
    "    if tflops_type in perf_data:\n",
    "        return perf_data[tflops_type]\n",
    "    elif 'TFLOPS32' in perf_data:\n",
    "        return perf_data['TFLOPS32']\n",
    "    elif 'TFLOPS16' in perf_data:\n",
    "        return perf_data['TFLOPS16']\n",
    "    else:\n",
    "        raise ValueError(\"No valid TFLOPS column found for the GPU.\")\n",
    "\n",
    "def recommend_gpu(scores, tflops_type):\n",
    "    pricing_df = pd.read_excel(os.path.join(get_root(), 'data', 'pricing', 'GCP gpus pricing.xlsx'))\n",
    "    pricing_df.columns = ['Region', 'GPU', 'Price']\n",
    "    gpu_prices = pricing_df.groupby('GPU')['Price'].mean().reset_index()\n",
    "    gpu_prices['Normalized_Price'] = normalize_data(gpu_prices['Price'])\n",
    "    \n",
    "    performance_df = pd.read_csv(os.path.join(get_root(), 'data', 'gpus.csv'))\n",
    "    \n",
    "    manual_map = {\n",
    "        'T4': 'T4',\n",
    "        'V100': 'Tesla V100-PCIE-16GB',\n",
    "        'P100': 'Tesla P100',\n",
    "        'K80': 'Tesla K80',\n",
    "    }\n",
    "    \n",
    "    gpu_prices['Mapped_GPU'] = gpu_prices['GPU'].apply(lambda x: manual_map.get(x, x))\n",
    "    performance_data = {row['name']: row for _, row in performance_df.iterrows()}\n",
    "    \n",
    "    merged_data = []\n",
    "    for _, row in gpu_prices.iterrows():\n",
    "        pricing_gpu = row['Mapped_GPU']\n",
    "        if pricing_gpu in performance_data:\n",
    "            perf_data = performance_data[pricing_gpu]\n",
    "            print(perf_data)\n",
    "            tflops_value = get_tflops_value(perf_data, tflops_type)\n",
    "            print(tflops_value)\n",
    "            tflops_per_watt = tflops_value / perf_data['tdp_watts']\n",
    "            merged_data.append({\n",
    "                'GPU': row['GPU'],\n",
    "                'Mapped_GPU': pricing_gpu,\n",
    "                'Price': row['Price'],\n",
    "                'Normalized_Price': row['Normalized_Price'],\n",
    "                'TDP_Watts': perf_data['tdp_watts'],\n",
    "                tflops_type: tflops_value,\n",
    "                'TFLOPS_per_Watt': tflops_per_watt\n",
    "            })\n",
    "    \n",
    "    merged_df = pd.DataFrame(merged_data)\n",
    "    \n",
    "    merged_df['Normalized_TFLOPS'] = normalize_data(merged_df[tflops_type])\n",
    "    merged_df['Normalized_TDP'] = normalize_data(merged_df['TDP_Watts'])\n",
    "    merged_df['Normalized_TFLOPS_per_Watt'] = normalize_data(merged_df['TFLOPS_per_Watt'])\n",
    "\n",
    "    merged_df['Price_Score'] = (1 - merged_df['Normalized_Price']) * scores['price']\n",
    "    merged_df['TFLOPS_Score'] = merged_df['Normalized_TFLOPS'] * scores['time']\n",
    "    merged_df['TDP_Score'] = merged_df['Normalized_TFLOPS_per_Watt'] * scores['co2']\n",
    "\n",
    "    merged_df['Total_Score'] = merged_df['Price_Score'] + merged_df['TFLOPS_Score'] + merged_df['TDP_Score']\n",
    "    \n",
    "    best_gpu = merged_df.sort_values('Total_Score', ascending=False).iloc[0]\n",
    "    \n",
    "    return best_gpu['Mapped_GPU']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                Tesla K80\n",
      "type                      gpu\n",
      "tdp_watts                 300\n",
      "TFLOPS32                4.113\n",
      "TFLOPS16                  NaN\n",
      "GFLOPS32/W              13.71\n",
      "GFLOPS16/W                NaN\n",
      "memory                   12.0\n",
      "source        techpowerup.com\n",
      "Name: 15, dtype: object\n",
      "##################################################\n",
      "name               Tesla P100\n",
      "type                      gpu\n",
      "tdp_watts                 250\n",
      "TFLOPS32                9.526\n",
      "TFLOPS16                19.05\n",
      "GFLOPS32/W               38.1\n",
      "GFLOPS16/W               76.2\n",
      "memory                   16.0\n",
      "source        techpowerup.com\n",
      "Name: 17, dtype: object\n",
      "##################################################\n",
      "name                                                         T4\n",
      "type                                                        gpu\n",
      "tdp_watts                                                    70\n",
      "TFLOPS32                                                  8.141\n",
      "TFLOPS16                                                  65.13\n",
      "GFLOPS32/W                                                116.3\n",
      "GFLOPS16/W                                                  930\n",
      "memory                                                     16.0\n",
      "source        https://www.nvidia.com/content/dam/en-zz/Solut...\n",
      "Name: 13, dtype: object\n",
      "##################################################\n",
      "name                                       Tesla V100-PCIE-16GB\n",
      "type                                                        gpu\n",
      "tdp_watts                                                   300\n",
      "TFLOPS32                                                  14.13\n",
      "TFLOPS16                                                  28.26\n",
      "GFLOPS32/W                                                 4.71\n",
      "GFLOPS16/W                                                 94.2\n",
      "memory                                                     16.0\n",
      "source        https://www.techpowerup.com/gpu-specs/tesla-v1...\n",
      "Name: 19, dtype: object\n",
      "##################################################\n",
      "With weights {'price': 0.3970128527963698, 'time': 0.3137746225923053, 'co2': 0.28921252461132496}, the recommended GPU is: T4\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "if __name__ == \"__main__\":\n",
    "    tflops_type = 'TFLOPS16'  # or 'TFLOPS16'\n",
    "    \n",
    "    num_samples = 1\n",
    "    results = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        weights = {\n",
    "            'price': random.uniform(0, 1),\n",
    "            'time': random.uniform(0, 1),\n",
    "            'co2': random.uniform(0, 1)\n",
    "        }\n",
    "        total = sum(weights.values())\n",
    "        weights = {k: v / total for k, v in weights.items()}  # Normalize to sum to 1\n",
    "        best_gpu = recommend_gpu(weights, tflops_type)\n",
    "        results.append((weights, best_gpu))\n",
    "    \n",
    "    # Print or save the results\n",
    "    for weights, gpu in results:\n",
    "        print(f\"With weights {weights}, the recommended GPU is: {gpu}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
